{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp segmentation_model_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "from toolz import compose\n",
    "from tensorflow.keras import losses, metrics, layers, models\n",
    "from deeplearning_image_pixelwise import data, config\n",
    "import attr\n",
    "\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "    \n",
    "\n",
    "if config.float_dtype == 'float16':\n",
    "    tf.keras.backend.set_floatx('float16')\n",
    "    tf.keras.backend.set_epsilon(1e-4)\n",
    "    policy = tensorflow.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    tensorflow.keras.mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "DATA_DIR = config.DATA_DIR\n",
    "TRAIN_DIR = config.TRAIN_DIR\n",
    "TRAIN_MASK_DIR = config.TRAIN_MASK_DIR\n",
    "VAL_DIR = config.VAL_DIR\n",
    "VAL_MASK_DIR = config.VAL_MASK_DIR\n",
    "N_CLASSES = config.N_CLASSES\n",
    "BATCH_SIZE = config.BATCH_SIZE\n",
    "IMG_HEIGHT, IMG_WIDTH = config.IMG_WIDTH, config.IMG_WIDTH\n",
    "EPOCHS = 10 \n",
    "\n",
    "buffer_size = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "BASE_N_FILTERS = 2\n",
    "DROPOUT_RATE = 0.5\n",
    "ACTIVATION = 'relu'\n",
    "INITIALIZER = 'glorot_normal'\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/deeplearning_image_pixelwise\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "val_dataset = data.load_dataset(VAL_DIR, VAL_MASK_DIR)\n",
    "train_dataset = data.load_dataset(TRAIN_MASK_DIR, TRAIN_MASK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def unet_forward_block(input_, n_filters, dropout_rate, activation, initializer):\n",
    "    conv_out = layers.Conv2D(n_filters, (3, 3), activation=activation, kernel_initializer=initializer, padding='same')(input_)\n",
    "    conv_out = layers.BatchNormalization()(conv_out)\n",
    "    conv_out = layers.Dropout(dropout_rate) (conv_out)\n",
    "    conv_out = layers.Conv2D(n_filters, (3, 3), activation=activation, kernel_initializer=initializer, padding='same') (conv_out)\n",
    "    conv_out = layers.BatchNormalization()(conv_out)\n",
    "    pool_out = layers.MaxPooling2D((2, 2)) (conv_out)\n",
    "    return conv_out, pool_out \n",
    "    \n",
    "    \n",
    "def unet_skip_connect_block(current, skip_connected, n_filters, dropout_rate, activation, initializer):\n",
    "    conv_current = layers.Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same') (current)\n",
    "    skip_connected_concat = layers.concatenate([conv_current, skip_connected])\n",
    "    skip_connected_concat = layers.Conv2D(2 * n_filters, (3, 3), activation=activation, kernel_initializer=initializer, padding='same') (skip_connected_concat)\n",
    "    skip_connected_concat = layers.BatchNormalization()(skip_connected_concat)\n",
    "    skip_connected_concat = layers.Dropout(dropout_rate) (skip_connected_concat)\n",
    "    skip_connected_concat = layers.Conv2D(2 * n_filters, (3, 3), activation=activation, kernel_initializer=initializer, padding='same') (skip_connected_concat)\n",
    "    return layers.BatchNormalization()(skip_connected_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metric - IoU\n",
    "\n",
    "Mean Intersection over Union is commonly used for evaluating segmentation models - it calculates mean IoU score over classes (like in scikit-learn 'macro' averaging scheme).\n",
    "This makes this metric care about each class equally, and not be overpowered by classes with many pixels, what happens to accuracy.\n",
    "\n",
    "MeanIOU from tf.keras.metrics can't handle logits (it operates on labels) so there was a need to write this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def tf_casted_sum(tensor, dtype=tf.uint8):\n",
    "    return tf.math.reduce_sum(tf.cast(tensor, dtype))\n",
    "\n",
    "\n",
    "def iou(masks, masks_logits_pred, category):\n",
    "    masks_pred = tf.cast(tf.math.argmax(masks_logits_pred, axis=-1), tf.int32)\n",
    "    positive = masks == category\n",
    "    negative = masks != category\n",
    "    positive_pred = masks_pred == category\n",
    "    negative_pred = masks_pred != category\n",
    "    intersection = tf_casted_sum(\n",
    "        tf.math.logical_and(positive_pred, positive[:,:,:,0])\n",
    "    )\n",
    "    union = tf_casted_sum(positive) + tf_casted_sum(positive_pred) - intersection\n",
    "    return tf.cond(union > 0, lambda: intersection / union, lambda: tf.ones((), dtype=tf.float32))\n",
    "\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Return the Intersection over Union (IoU) score.\n",
    "    Args:\n",
    "        y_true: the expected y values as a one-hot\n",
    "        y_pred: the predicted y values as a one-hot or softmax output\n",
    "    Returns:\n",
    "        the scalar IoU value (mean over all labels)\n",
    "    \"\"\"\n",
    "    # get number of labels to calculate IoU for\n",
    "    num_labels = y_pred.shape[-1]\n",
    "    # initialize a variable to store total IoU in\n",
    "    total_iou = 0 #tf.zeros((),)\n",
    "    # iterate over labels to calculate IoU for\n",
    "    for label in range(num_labels):\n",
    "        total_iou = total_iou + iou(y_true, y_pred, label)\n",
    "    # divide total IoU by number of labels to get mean IoU\n",
    "    return total_iou / num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def accuracy(y_true, y_pred_logits):\n",
    "    y_true = tf.cast(y_true, tf.uint8)[:,:,0]\n",
    "    y_pred = tf.cast(tf.math.argmax(y_pred_logits, axis=-1), tf.uint8)\n",
    "    return tf.math.reduce_mean(tf.cast(y_pred == y_true, config.float_dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_default_callbacks():\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='weights.{epoch:02d}-{mean_iou:.3f}.hdf5',\n",
    "        monitor='mean_iou'\n",
    "    )\n",
    "    tensorboard_training_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='logs', histogram_freq=0, write_images=False,\n",
    "        update_freq=100, profile_batch=2, embeddings_freq=0,\n",
    "        embeddings_metadata=None\n",
    "    )\n",
    "    tensorboard_epoch_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='logs', histogram_freq=0, write_images=False,\n",
    "        update_freq='epoch', profile_batch=2, embeddings_freq=0,\n",
    "        embeddings_metadata=None\n",
    "    )\n",
    "    return [model_checkpoint_callback]#, tensorboard_training_callback, tensorboard_epoch_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def build_segmentation_model(\n",
    "        input_shape,\n",
    "        n_classes,\n",
    "        base_n_filters=BASE_N_FILTERS,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        activation=ACTIVATION,\n",
    "        initializer=INITIALIZER\n",
    "    ):\n",
    "    # Build U-Net segmentation_model\n",
    "    inputs = layers.Input(input_shape)\n",
    "    \n",
    "    c1, p1 = unet_forward_block(inputs, 2 * base_n_filters, dropout_rate, activation, initializer)\n",
    "    c2, p2 = unet_forward_block(p1, 4 * base_n_filters, dropout_rate, activation, initializer)\n",
    "    c3, p3 = unet_forward_block(p2, 8 * base_n_filters, dropout_rate, activation, initializer)\n",
    "    c4, p4 = unet_forward_block(p3, 8 * base_n_filters, dropout_rate, activation, initializer)\n",
    "    c5, __ = unet_forward_block(p4, 16 * base_n_filters, dropout_rate, activation, initializer)\n",
    "\n",
    "    #concating starts\n",
    "    u6 = unet_skip_connect_block(c5, c4, 2 * base_n_filters, dropout_rate, activation, initializer)\n",
    "    u7 = unet_skip_connect_block(u6, c3, 2 * base_n_filters, dropout_rate, activation, initializer)\n",
    "    u8 = unet_skip_connect_block(u7, c2, 2 * base_n_filters, dropout_rate, activation, initializer)\n",
    "    u9 = unet_skip_connect_block(u8, c1, base_n_filters, dropout_rate, activation, initializer)\n",
    "\n",
    "    out = layers.Conv2D(n_classes, (1, 1)) (u9)\n",
    "    # for some reason SparseCategoricalCrossEntropy fails if the output is fp16\n",
    "    out = tf.cast(out, tf.float32)\n",
    "    return models.Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "\n",
    "def setup_segmentation_model(\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "        n_classes=N_CLASSES,\n",
    "        loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tensorflow.keras.optimizers.Adam(LEARNING_RATE),\n",
    "        metrics=[accuracy, mean_iou]\n",
    "    ):\n",
    "    segmentation_model = build_segmentation_model(input_shape, n_classes)\n",
    "    segmentation_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return segmentation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 224, 224, 4)  112         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 4)  16          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 224, 224, 4)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 4)  148         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 4)  16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 112, 112, 4)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 8)  296         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 8)  32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 112, 112, 8)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 8)  584         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 8)  32          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 8)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 16)   1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 56, 56, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 16)   2320        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 32)   4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 28, 28, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 32)   9248        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 14, 14, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 64)   36928       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 14, 14, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 28, 28, 4)    1028        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28, 28, 36)   0           conv2d_transpose[0][0]           \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 8)    2600        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 28, 28, 8)    32          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 28, 28, 8)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 8)    584         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 8)    32          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 56, 56, 4)    132         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 56, 56, 20)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 56, 56, 8)    1448        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 56, 56, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 56, 56, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 56, 56, 8)    584         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 56, 56, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 112, 112, 4)  132         batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 112, 112, 12) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 112, 112, 8)  872         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 112, 112, 8)  32          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 112, 112, 8)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 112, 112, 8)  584         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 112, 112, 8)  32          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 224, 224, 2)  66          batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 224, 224, 6)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 224, 224, 4)  220         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 224, 224, 4)  16          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 224, 224, 4)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 224, 224, 4)  148         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 224, 224, 4)  16          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 224, 224, 184 920         batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [(None, 224, 224, 18 0           conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 84,474\n",
      "Trainable params: 83,866\n",
      "Non-trainable params: 608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "segmentation_model = setup_segmentation_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(segmentation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = train_dataset.take(2 ** 14)\n",
    "#val_dataset = val_dataset.take(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When passing an infinitely repeating dataset, you must specify the `steps_per_epoch` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-db1a3cfa7a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_default_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/etc/conda/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/etc/conda/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m           \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           epochs=0)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       steps_per_epoch = (\n",
      "\u001b[0;32m/etc/conda/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36minfer_steps_for_dataset\u001b[0;34m(model, dataset, steps, epochs, steps_name)\u001b[0m\n\u001b[1;32m   1750\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFINITE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m     raise ValueError('When passing an infinitely repeating dataset, you '\n\u001b[0;32m-> 1752\u001b[0;31m                      'must specify the `%s` argument.' % (steps_name,))\n\u001b[0m\u001b[1;32m   1753\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: When passing an infinitely repeating dataset, you must specify the `steps_per_epoch` argument."
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "segmentation_model.fit(\n",
    "    train_dataset.batch(BATCH_SIZE).shuffle(buffer_size).repeat(), \n",
    "    validation_data=val_dataset.batch(BATCH_SIZE),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=get_default_callbacks(),\n",
    "    steps_per_epoch=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
